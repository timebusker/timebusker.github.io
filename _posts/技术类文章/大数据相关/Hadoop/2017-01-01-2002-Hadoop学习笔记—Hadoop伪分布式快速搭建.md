---
layout:     post
title:      Hadoop学习笔记 — Hadoop伪分布式快速搭建
date:       2018-03-15
author:     timebusker
header-img: img/home-bg.jpg
catalog: true
tags:
    - Hadoop
---

> Hadoop学习笔记 — Hadoop伪分布式快速搭建

> **hadoop fs -put 1902.gz hdfs://timebusker:9000/**

#### Hadoop伪分布式模式——**Pseudo-Distributed**   

##### 配置免密登录

- Linux下生成密钥
  通过`ssh-keygen -t rsa`生成密钥和公钥

- 导入公钥到认证文件,更改权限
  导入本机   
  `cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`
  
  更改权限
  `
  chmod 700 ~/.ssh
  chmod 600 ~/.ssh/authorized_keys 

##### JDK环境变量配置 
```
# /root/.bashrc  设置成当前用户
JAVA_HOME=/usr/java/jdk1.8.0_171-i586
PATH=$PATH:$JAVA_HOME/bin/
export JAVA_HOME PATH 
```

##### Hadoop环境变量配置   
```
HADOOP_HOME=/root/hadoop-2.9.0
PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

export HADOOP_HOME PATH
```  
##### core-site.xml  
```
<configuration>  
  <!--
  【这里的值指的是默认的HDFS路径。这里只有一个HDFS集群，在这里指定！该值来自于hdfs-site.xml中的配置】
  -->        
  <property>        
     <name>fs.defaultFS</name>        
     <value>hdfs://localhost</value>        
  </property>  
  <!--
  【这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录。用户也可以自己单独指定这三类节点的目录】
   存储在本地磁盘
  -->          
  <property>        
       <name>hadoop.tmp.dir</name>       
       <value>/tmp/hdpcentos/yarn/yarn_data/tmp</value>   
   </property>
</configuration> 

<!-- 用户授权代理ProxyUser -->
<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
<property>
	<name>hadoop.proxyuser.root.groups</name>
	<value>*</value>
</property>
<property>
	<name>hadoop.proxyuser.root.users</name>
	<value>*</value>
</property>
``` 
##### hdfs-site.xml    
```
<configuration>  
    <!--【指定DataNode存储block的副本数量。默认值是3个。】-->    
    <property>    
      <name>dfs.replication</name>    
       <value>2</value>    
    </property>          
    <property>    
       <name>dfs.permissions</name>    
      <value>false</value>    
   </property>    
   <property>    
      <name>dfs.permissions.enabled</name>    
      <value>false</value>    
   </property>  
   <property>
     <name>dfs.namenode.name.dir</name>
     <value>/opt/hadoop-data/namenode/name</value>
   </property>
   <property>
      <name>dfs.datanode.data.dir</name>
     <value>/opt/hadoop-data/datanode/name</value>
</property>
</configuration>  
```

##### mapred-site.xml

```
<configuration>
	<!--指定mapreduce运行在yarn框架上-->
	<property>
			<name>mapreduce.framework.name</name>
			<value>yarn</value>
	</property>
	<!--指定MR总内存大小，默认是1536M，机器内存小于改值需要调整-->
	<property>
			<name>yarn.app.mapreduce.am.resource.mb</name>
			<value>256</value>
	</property>
</configuration>
```

##### yarn-site.xml

```
<configuration>
	<!--配置了yarn的默认混洗方式，选择为mapreduce的默认混洗算法-->
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<!--指定Resourcemanager运行在哪个节点上-->
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>127.0.0.1</value>
	</property>
	<!--指定nodemanager运行在哪个节点上-->
	<property>
		<name>yarn.nodemanager.hostname</name>
		<value>127.0.0.1</value>
	</property>
	<!--单个任务可申请的最小内存资源量单位：M-->
	<property>
		<name>yarn.scheduler.minimum-allocation-mb</name>
		<value>256</value>
	</property>
	<!--单个任务可申请的最大内存资源量,单位：M-->
	<property>
		<name>yarn.scheduler.maximum-allocation-mb</name>
		<value>1024</value>
	</property>
	<!--NodeManager总的可用物理内存单位：M-->
	<property>
		<name>yarn.nodemanager.resource.memory-mb</name>
		<value>2048</value>
	</property>
	<!--是否启用虚拟内存检查虚拟内存倍数默认2.1，如果开启虚拟内存检查（vmem-check-enabled=true），
	虚拟内存倍数（vmem-pmem-ratio=2.1）不做调整，容易出现虚拟内存溢出，一般解
	决方案是调整这两个参数-->
	<property>
		<name>yarn.nodemanager.vmem-check-enabled</name>
		<value>false</value>
	</property>
</configuration>
```

##### 启动Hadoop  

- 格式化namenode的`主要三个作用`：
```
# 创建一个全新的元数据存储目录
# 生成记录元数据的文件fsimage
# 创建磁盘目录

./bin/hdfs namenode -format

# 启动服务
./sbin/start-all.sh

```

- 启动NameNode：`hadoop-daemon.sh start namenode`
- 启动DataNode：`hadoop-daemon.sh start datanode`
- 启动SecondaryNameNode：`hadoop-daemon.sh start secondarynamenode`
- 启动Resourcemanager：`yarn-daemon.sh start resourcemanager`
- 启动nodemanager：`yarn-daemon.sh start nodemanager`

##### 开启历史记录服务

```
mr-jobhistory-daemon.sh start historyserver

历史记录 Web客户端:http://localhost:19888/
```

##### Hadoop配置文件详解

- [Hadoop之——hadoop下配置文件说明](https://blog.csdn.net/l1028386804/article/details/51372663);

- [Hadoop配置文件参数详解](https://www.cnblogs.com/yinghun/p/6230436.html);


#### 集群测试
```
hadoop fs -put 1902.gz hdfs://timebusker:9000/

yarn jar /opt/hadoop-2.8.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar  pi 4 100
```

#### 遗留问题

- 问题一 :并不会影响系统运行

- ————[实际解决问题的办法](https://blog.csdn.net/qq_38318622/article/details/80521471)
```
[root@timebusker sbin]# yarn jar /root/hadoop-2.9.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar  pi 4 100
Number of Maps  = 4
Samples per Map = 100
18/06/13 19:02:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
```  